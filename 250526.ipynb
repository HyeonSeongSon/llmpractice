{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "182c5d5b",
   "metadata": {},
   "source": [
    "ì„¤ì • / ì•± / vscode, Miniconda3, pythonì„ ì œê±°\n",
    "ì‚¬ìš©ìê³„ì • í´ë” .conda .ipython .vscode .miniconda3 í´ë”ì™¸, condarc íŒŒì¼ ì œê±°\n",
    "C:\\User"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "266f1213",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in c:\\users\\playdata\\miniconda3\\envs\\env1\\lib\\site-packages (0.3.25)\n",
      "Requirement already satisfied: langchain-openai in c:\\users\\playdata\\miniconda3\\envs\\env1\\lib\\site-packages (0.3.18)\n",
      "Requirement already satisfied: python-dotenv in c:\\users\\playdata\\miniconda3\\envs\\env1\\lib\\site-packages (1.1.0)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.58 in c:\\users\\playdata\\miniconda3\\envs\\env1\\lib\\site-packages (from langchain) (0.3.61)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in c:\\users\\playdata\\miniconda3\\envs\\env1\\lib\\site-packages (from langchain) (0.3.8)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.1.17 in c:\\users\\playdata\\miniconda3\\envs\\env1\\lib\\site-packages (from langchain) (0.3.42)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in c:\\users\\playdata\\miniconda3\\envs\\env1\\lib\\site-packages (from langchain) (2.11.3)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\playdata\\miniconda3\\envs\\env1\\lib\\site-packages (from langchain) (2.0.40)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\playdata\\miniconda3\\envs\\env1\\lib\\site-packages (from langchain) (2.32.3)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\playdata\\miniconda3\\envs\\env1\\lib\\site-packages (from langchain) (6.0.2)\n",
      "Requirement already satisfied: openai<2.0.0,>=1.68.2 in c:\\users\\playdata\\miniconda3\\envs\\env1\\lib\\site-packages (from langchain-openai) (1.78.1)\n",
      "Requirement already satisfied: tiktoken<1,>=0.7 in c:\\users\\playdata\\miniconda3\\envs\\env1\\lib\\site-packages (from langchain-openai) (0.9.0)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in c:\\users\\playdata\\miniconda3\\envs\\env1\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.58->langchain) (9.1.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\playdata\\miniconda3\\envs\\env1\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.58->langchain) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in c:\\users\\playdata\\miniconda3\\envs\\env1\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.58->langchain) (24.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in c:\\users\\playdata\\miniconda3\\envs\\env1\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.58->langchain) (4.12.2)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\playdata\\miniconda3\\envs\\env1\\lib\\site-packages (from langsmith<0.4,>=0.1.17->langchain) (0.27.0)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\playdata\\miniconda3\\envs\\env1\\lib\\site-packages (from langsmith<0.4,>=0.1.17->langchain) (3.10.16)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\users\\playdata\\miniconda3\\envs\\env1\\lib\\site-packages (from langsmith<0.4,>=0.1.17->langchain) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in c:\\users\\playdata\\miniconda3\\envs\\env1\\lib\\site-packages (from langsmith<0.4,>=0.1.17->langchain) (0.23.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\playdata\\miniconda3\\envs\\env1\\lib\\site-packages (from openai<2.0.0,>=1.68.2->langchain-openai) (4.6.2)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\playdata\\miniconda3\\envs\\env1\\lib\\site-packages (from openai<2.0.0,>=1.68.2->langchain-openai) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\users\\playdata\\miniconda3\\envs\\env1\\lib\\site-packages (from openai<2.0.0,>=1.68.2->langchain-openai) (0.9.0)\n",
      "Requirement already satisfied: sniffio in c:\\users\\playdata\\miniconda3\\envs\\env1\\lib\\site-packages (from openai<2.0.0,>=1.68.2->langchain-openai) (1.3.0)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\playdata\\miniconda3\\envs\\env1\\lib\\site-packages (from openai<2.0.0,>=1.68.2->langchain-openai) (4.67.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\playdata\\miniconda3\\envs\\env1\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.1 in c:\\users\\playdata\\miniconda3\\envs\\env1\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.1)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\playdata\\miniconda3\\envs\\env1\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\playdata\\miniconda3\\envs\\env1\\lib\\site-packages (from requests<3,>=2->langchain) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\playdata\\miniconda3\\envs\\env1\\lib\\site-packages (from requests<3,>=2->langchain) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\playdata\\miniconda3\\envs\\env1\\lib\\site-packages (from requests<3,>=2->langchain) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\playdata\\miniconda3\\envs\\env1\\lib\\site-packages (from requests<3,>=2->langchain) (2025.1.31)\n",
      "Requirement already satisfied: greenlet>=1 in c:\\users\\playdata\\miniconda3\\envs\\env1\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.2.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in c:\\users\\playdata\\miniconda3\\envs\\env1\\lib\\site-packages (from tiktoken<1,>=0.7->langchain-openai) (2024.11.6)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\playdata\\miniconda3\\envs\\env1\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.0.2)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\playdata\\miniconda3\\envs\\env1\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\playdata\\miniconda3\\envs\\env1\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.58->langchain) (3.0.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\playdata\\miniconda3\\envs\\env1\\lib\\site-packages (from tqdm>4->openai<2.0.0,>=1.68.2->langchain-openai) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install langchain langchain-openai python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1996ce5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sk-p'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "load_dotenv()\n",
    "os.getenv('OPENAI_API_KEY')[:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3efcacbf",
   "metadata": {},
   "source": [
    "Langchainì˜ í•µì‹¬ ì»´í¬ë„ŒíŠ¸ : ëª¨ë¸ í˜¸ì¶œê³„ë¥¼ êµ¬ì„±í•˜ëŠ” ì¶”ìƒí™” ìš”ì†Œë¥¼ ì œê³µ\n",
    "```\n",
    "    - PromptTemplate : LLMì— ë³´ë‚¼ ì…ë ¥ í”„ë¡¬í”„íŠ¸\n",
    "    - ChatOpenAI : openaiì˜ GPT - ëª¨ë¸ í˜¸ì¶œ\n",
    "    - Runnable : ì‹¤í–‰ê°€ëŠ¥í•œ ê°ì²´ì— ëŒ€í•œ ê³µí†µ ì¸í„°í˜ì´ìŠ¤ -> invoke() ë§¤ì„œë“œë¥¼ í†µí•´ì„œ ì…ë ¥ê³¼ ì¶œë ¥ì„ ì§€ì›\n",
    "    - StrOutPutParser : ë¬¸ìì—´ ì¶œë ¥ íŒŒì„œ\n",
    "íŒŒì´í”„ë¡œ ì—°ê²° ê°€ëŠ¥... ex) prompt | llm | strparser\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f2d3f5b",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "140c724e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ì»¤í”¼ì œí’ˆì„ ìƒì‚°í•˜ëŠ” íšŒì‚¬ì´ë¦„ì€ ë­˜ë¡œ í•˜ë©´ ì¢‹ì„ê¹Œ?'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "template = '{product}ì œí’ˆì„ ìƒì‚°í•˜ëŠ” íšŒì‚¬ì´ë¦„ì€ ë­˜ë¡œ í•˜ë©´ ì¢‹ì„ê¹Œ?'\n",
    "prompt = PromptTemplate.from_template(template)\n",
    "formated_prompt = prompt.format(product = 'ì»¤í”¼')\n",
    "formated_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "38804ad1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='ì•ˆë…•í•˜ì„¸ìš”! ì–´ë–»ê²Œ ë„ì™€ë“œë¦´ê¹Œìš”?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 10, 'prompt_tokens': 9, 'total_tokens': 19, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_34a54ae93c', 'id': 'chatcmpl-BbGg2MWS8ekVWC4EO16lMHli4UAuU', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--1ab0df0e-8b72-46de-aa72-67ed04891e26-0', usage_metadata={'input_tokens': 9, 'output_tokens': 10, 'total_tokens': 19, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "# ìœ„ì—ì„œ ì„ ì–¸í–ˆê¸° ë•Œë¬¸ì— keyê°’ì„ ì…ë ¥í•˜ì§€ ì•Šì•„ë„ ë¨\n",
    "llm=ChatOpenAI(model='gpt-4o-mini', temperature=0) # Runnable ê°ì²´ --> invoke()\n",
    "response = llm.invoke([('human','ì•ˆë…•')])\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7fd26410",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ì•ˆë…•í•˜ì„¸ìš”! ì–´ë–»ê²Œ ë„ì™€ë“œë¦´ê¹Œìš”?'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ë¬¸ìì—´ ì¶œë ¥ íŒŒì„œ Runnable ê°ì²´ -invoke\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "parser = StrOutputParser()\n",
    "parser_text= parser.invoke(response)\n",
    "parser_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3732e304",
   "metadata": {},
   "source": [
    "LangChain Expression Language(LCEL) ë‹¨ì¼ ì²´ì¸ ì‹¤í–‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "16974841",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì»¤í”¼ ì œí’ˆì„ ìƒì‚°í•˜ëŠ” íšŒì‚¬ ì´ë¦„ìœ¼ë¡œëŠ” ë‹¤ìŒê³¼ ê°™ì€ ì•„ì´ë””ì–´ë¥¼ ê³ ë ¤í•´ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤:\n",
      "\n",
      "1. **ì»¤í”¼ì˜ ì •ì›** (Garden of Coffee)\n",
      "2. **ì•„ì¹¨ì˜ í–¥ê¸°** (Morning Aroma)\n",
      "3. **ì»¤í”¼ì˜ ì˜ˆìˆ ** (Art of Coffee)\n",
      "4. **ì»¤í”¼ ë§ˆë²•** (Coffee Magic)\n",
      "5. **í•œ ì”ì˜ í–‰ë³µ** (Cup of Joy)\n",
      "6. **ì»¤í”¼ ì´ì•¼ê¸°** (Coffee Tales)\n",
      "7. **ì»¤í”¼ì˜ ì—¬ì •** (Journey of Coffee)\n",
      "8. **í”„ë¦¬ë¯¸ì—„ ë¡œìŠ¤íŠ¸** (Premium Roast)\n",
      "9. **ì»¤í”¼ì˜ ë¯¸ì†Œ** (Coffee Smile)\n",
      "10. **ì»¤í”¼ì˜ ìˆœê°„** (Moments of Coffee)\n",
      "\n",
      "ì´ë¦„ì€ ë¸Œëœë“œì˜ ì´ë¯¸ì§€ì™€ ëª©í‘œì— ë§ê²Œ ì„ íƒí•˜ëŠ” ê²ƒì´ ì¤‘ìš”í•˜ë‹ˆ, ì—¬ëŸ¬ ê°€ì§€ ì•„ì´ë””ì–´ë¥¼ ì¡°í•©í•´ë³´ê±°ë‚˜ ë³€í˜•í•´ë³´ëŠ” ê²ƒë„ ì¢‹ìŠµë‹ˆë‹¤!\n"
     ]
    }
   ],
   "source": [
    "chain = prompt | llm | parser  # runnable ê°ì²´ --> invoke\n",
    "result = chain.invoke([\"product\",\"coffee\"])\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2422f49f",
   "metadata": {},
   "source": [
    "Langchainì„ í™œìš©í•œ ëª¨ë¸ ì‚¬ìš©, ë¹„ìš© ëª¨ë‹ˆí„°ë§ ë° ê°œì„± ì „ëµ\n",
    "```\n",
    "Langchainì„ í™œìš©í•œ ëª¨ë¸ ì‚¬ìš©, ë¹„ìš©ëª¨ë‹ˆí„°ë§ ë° ìºì‹± ì „ëµ\n",
    "    GPT-4o-mini GPT 3.5-Turbo ë¹„ìš©ì´ 60% ì €ë ´\n",
    "    Langchain v0.3ë¶€í„° openAIê°€ ë³„ë„ íŒ¨í‚¤ì§€ë¡œ ë¶„ë¦¬ í•„ìš” íŒ¨í‚¤ì§€ë¥¼ ì„¤ì¹˜ langchain-openai í•„ìš”\n",
    "    í† í° ì‚¬ìš©ëŸ‰ ì¶”ì •, ìºì‹±ì„ ìœ„í•œ LangChain-communityë„ ë³„ë„ ì„¤ì¹˜\n",
    "    í™˜ê²½ë³€ìˆ˜ ë³€ìˆ˜ ê´€ë¦¬ íŒ¨í‚¤ì§€ python-dotevn\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eb680953",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain-openai in c:\\users\\playdata\\miniconda3\\envs\\env1\\lib\\site-packages (0.3.18)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement langchain-cummunity (from versions: none)\n",
      "ERROR: No matching distribution found for langchain-cummunity\n"
     ]
    }
   ],
   "source": [
    "%pip install langchain-openai langchain-cummunity python-dotenv openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "68392bfe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d74d962a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'LangChainì€ ë‹¤ì–‘í•œ ì–¸ì–´ ëª¨ë¸ê³¼ ë°ì´í„° ì†ŒìŠ¤ë¥¼ ì—°ê²°í•˜ì—¬ ìì—°ì–´ ì²˜ë¦¬ ì• í”Œë¦¬ì¼€ì´ì…˜ì„ ì‰½ê²Œ êµ¬ì¶•í•  ìˆ˜ ìˆë„ë¡ ì§€ì›í•˜ëŠ” í”„ë ˆì„ì›Œí¬ì…ë‹ˆë‹¤.'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "llm = ChatOpenAI(model='gpt-4o-mini', temperature=0.7)\n",
    "prompt = 'LangChainì— ëŒ€í•´ í•œë¬¸ì¥ìœ¼ë¡œ ì„¤ëª…í•´ì¤˜'\n",
    "result = llm.invoke(prompt)\n",
    "result.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5615b8fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_tokens': 18,\n",
       " 'output_tokens': 35,\n",
       " 'total_tokens': 53,\n",
       " 'input_token_details': {'audio': 0, 'cache_read': 0},\n",
       " 'output_token_details': {'audio': 0, 'reasoning': 0}}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ì‚¬ìš©ëŸ‰\n",
    "result.usage_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f768899c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì‘ë‹µ1 ì£„ì†¡í•˜ì§€ë§Œ, ì‹¤ì‹œê°„ ...\n",
      "ì‘ë‹µ2 ë­ì²´ì¸(RLangC ...\n",
      "ì´ í† í°ìˆ˜ :  737\n",
      "í”„ë¡¬í”„íŠ¸ í† í°ìˆ˜ :  37\n",
      "ì‘ë‹µí† í°ìˆ˜ :  700\n",
      "ë¹„ìš©ê³„ì‚°(USD) :  0.00042555\n"
     ]
    }
   ],
   "source": [
    "# ì½œë°±í•¨ìˆ˜ë¥¼ í†µí•œ ëˆ„ì  í† í° ì¶”ì (get_openai_callback)\n",
    "from langchain_community.callbacks import get_openai_callback\n",
    "with get_openai_callback() as cb:\n",
    "    # ì²«ë²ˆì§¸ í˜¸ì¶œ\n",
    "    res1 = llm.invoke('ì„œìš¸ì˜ ì˜¤ëŠ˜ ë‚ ì”¨ëŠ” ì–´ë–¤ì§€ ì•Œë ¤ì¤˜')\n",
    "    print('ì‘ë‹µ1', res1.content[:10], '...')\n",
    "    # ë‘ë²ˆì§¸ í˜¸ì¶œ\n",
    "    res2 = llm.invoke('íŒŒì´ì¬ìœ¼ë¡œ ë­ì²´ì¸ ì‚¬ìš©ë²• ì•Œë ¤ì¤˜')\n",
    "    print('ì‘ë‹µ2', res2.content[:10], '...')\n",
    "\n",
    "# ëˆ„ì  í† í° ì‚¬ìš©ëŸ‰ ì¶œë ¥ ì½œë°± cbì—ëŠ” ë¸”ë¡ ì „ì²´ í† í° ì‚¬ìš©ëŸ‰ì´ ëˆ„ì \n",
    "# ì´ í† í°ìˆ˜\n",
    "print('ì´ í† í°ìˆ˜ : ',cb.total_tokens)\n",
    "# í”„ë¡¬í”„íŠ¸ í† í°ìˆ˜\n",
    "print('í”„ë¡¬í”„íŠ¸ í† í°ìˆ˜ : ', cb.prompt_tokens)\n",
    "# ì‘ë‹µ í† í°ìˆ˜\n",
    "print('ì‘ë‹µí† í°ìˆ˜ : ', cb.completion_tokens)\n",
    "# ë¹„ìš©ê³„ì‚°\n",
    "print('ë¹„ìš©ê³„ì‚°(USD) : ', cb.total_cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "494b1197",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LangChain ì˜ LLM ì‘ë‹µìºì‹± (InMemorry Cache, SQLiteCache)\n",
    "# ë™ì¼í•œ ì§ˆë¬¸ì€ ì €ì¥í•´ ë’€ë‹¤ê°€ ì‘ë‹µì— ì‚¬ìš©\n",
    "from langchain_core.caches import InMemoryCache\n",
    "from langchain_core.globals import set_llm_cache\n",
    "# InMemorryCache ì„¤ì •\n",
    "set_llm_cache(InMemoryCache())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b589328a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì‘ë‹µ1 : ë¬¼ê³ ê¸°ê°€ í•™êµì— ê°€ë©´ ë­ë¼ê³  ë¶€ë¥¼ê¹Œìš”?\n",
      "\n",
      "\"í”¼ì‹œ ìŠ¤ì¿¨!\" ğŸŸğŸ˜„\n",
      "--------------------------------------------------\n",
      "ì‘ë‹µ2 : ë¬¼ê³ ê¸°ê°€ í•™êµì— ê°€ë©´ ë­ë¼ê³  ë¶€ë¥¼ê¹Œìš”?\n",
      "\n",
      "\"í”¼ì‹œ ìŠ¤ì¿¨!\" ğŸŸğŸ˜„\n",
      "--------------------------------------------------\n",
      "ì‘ë‹µ3 : ë¬¼ë¡ ì´ì£ ! \n",
      "\n",
      "ì™œ ì»´í“¨í„°ëŠ” ë°”ë‹¤ë¥¼ ì‹«ì–´í• ê¹Œìš”?\n",
      "\n",
      "ë°”ë‹¤ì— ê°€ë©´ í•­ìƒ \"ë²„ê·¸\"ê°€ ìƒê¸°ë‹ˆê¹Œìš”! ğŸ›ğŸ’»\n",
      "\n",
      "ì¬ë¯¸ìˆìœ¼ì…¨ë‚˜ìš”? ë‹¤ë¥¸ ìœ ë¨¸ë„ ì›í•˜ì‹œë©´ ë§ì”€í•´ ì£¼ì„¸ìš”!\n"
     ]
    }
   ],
   "source": [
    "# ìºì‹œ ì‚¬ìš© ì „í›„ë¥¼ ë¹„êµ, ê°™ì€ ì§ˆë¬¸ì„ ë‘ë²ˆ í˜¸ì¶œ\n",
    "query = 'ì¬ë¯¸ìˆëŠ” ìœ ë¨¸ í•˜ë‚˜ ì•Œë ¤ì¤˜'\n",
    "# ì²« ë²ˆì§¸ í˜¸ì¶œ (ìºì‹œì— ì—†ìœ¼ë©´ api í˜¸ì¶œ ë°œìƒ)\n",
    "result1 = llm.invoke(query)\n",
    "print(f'ì‘ë‹µ1 : {result1.content}')\n",
    "print('-'*50)\n",
    "# ë‘ ë²ˆì§¸ í˜¸ì¶œ(ë™ì¼í•œ query, ìºì„œë¥¼ í™•ì¸í•˜ê³  ë™ì¼ ì§ˆë¬¸í•˜ë©´ api ë¯¸í˜¸ì¶œ)\n",
    "result2 = llm.invoke(query)\n",
    "print(f'ì‘ë‹µ2 : {result2.content}')\n",
    "print('-'*50)\n",
    "query = query + '?'\n",
    "# ì„¸ ë²ˆì§¸ í˜¸ì¶œ(!ê°€ ì¶”ê°€ëœ query)\n",
    "result3 = llm.invoke(query)\n",
    "print(f'ì‘ë‹µ3 : {result3.content}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c9b8aa93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì²«ë²ˆì§¸ í˜¸ì¶œì‹œê°„ : 4.591396808624268\n",
      "ë‘ë²ˆì§¸ í˜¸ì¶œì‹œê°„ : 0.0009007453918457031\n"
     ]
    }
   ],
   "source": [
    "# ì‹¤í–‰ì‹œê°„ ì¸¡ì •\n",
    "import time\n",
    "# ì²« ë²ˆì§¸ í˜¸ì¶œ ì‹œê°„\n",
    "query = 'ì˜¤ëŠ˜ ì ì‹¬ ë©”ë‰´ ì¶”ì²œ í•´ì¤˜!'\n",
    "start = time.time(); llm.invoke(query); end = time.time()\n",
    "print(f'ì²«ë²ˆì§¸ í˜¸ì¶œì‹œê°„ : {end-start}')\n",
    "\n",
    "start = time.time(); llm.invoke(query); end = time.time()\n",
    "print(f'ë‘ë²ˆì§¸ í˜¸ì¶œì‹œê°„ : {end-start}')\n",
    "\n",
    "# InMemorry ë°©ì‹ì€ ì–´í”Œë¦¬ì¼€ì´ì…˜ì„ ì¢…ë£Œí•˜ë©´ ì €ì¥ëœ ë‚´ìš©ì´ ë‚ ë¼ê°„ë‹¤"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3de89fcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì²« ë²ˆì§¸ í˜¸ì¶œì‹œê°„ : 4.121056795120239\n",
      "ì‘ë‹µ1 : ë¬¼ë¡ ì´ì£ ! ì €ë… ë©”ë‰´ë¡œ ëª‡ ê°€ì§€ ì¶”ì²œí•´ë“œë¦´ê²Œìš”.\n",
      "\n",
      "1. **ëœì¥ì°Œê°œì™€ ë°¥**: í•œêµ­ì˜ ì „í†µì ì¸ ëœì¥ì°Œê°œì— ë°¥ì„ ê³ë“¤ì—¬ ê°„ë‹¨í•˜ë©´ì„œë„ ë§›ìˆëŠ” í•œ ë¼ë¥¼ ì¦ê¸¸ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "2. **ë¶ˆê³ ê¸°**: ì–‘ë…ëœ ì†Œê³ ê¸°ë¥¼ ë³¶ì•„ë‚´ì–´ ìŒˆì±„ì†Œì™€ í•¨ê»˜ ë¨¹ìœ¼ë©´ í›Œë¥­í•œ ì €ë…ì´ ë©ë‹ˆë‹¤.\n",
      "\n",
      "3. **ì¡ì±„**: ë‹¹ë©´ê³¼ ë‹¤ì–‘í•œ ì±„ì†Œ, ê³ ê¸°ë¥¼ ë³¶ì•„ ë§Œë“  ì¡ì±„ëŠ” ë§›ë„ ì¢‹ê³  ì˜ì–‘ë„ í’ë¶€í•©ë‹ˆë‹¤.\n",
      "\n",
      "4. **í•´ë¬¼íŒŒì „**: ë¹„ ì˜¤ëŠ” ë‚ ì— íŠ¹íˆ ì˜ ì–´ìš¸ë¦¬ëŠ” í•´ë¬¼íŒŒì „ì€ ê°„ë‹¨í•˜ê²Œ ë§Œë“¤ ìˆ˜ ìˆê³ , ë§‰ê±¸ë¦¬ì™€ í•¨ê»˜í•˜ë©´ ë”ìš± ì¢‹ìŠµë‹ˆë‹¤.\n",
      "\n",
      "5. **ì¹˜í‚¨**: ë°”ì‚­í•˜ê²Œ íŠ€ê¸´ ì¹˜í‚¨ì— ë‹¤ì–‘í•œ ì‚¬ì´ë“œ ë©”ë‰´ë¥¼ ê³ë“¤ì—¬ ì¦ê¸¸ ìˆ˜ ìˆëŠ” ì €ë…ë„ ì¢‹ìŠµë‹ˆë‹¤.\n",
      "\n",
      "ì–´ë–¤ ë©”ë‰´ê°€ ë§ˆìŒì— ë“œì„¸ìš”? ì¶”ê°€ë¡œ ë‹¤ë¥¸ ì•„ì´ë””ì–´ê°€ í•„ìš”í•˜ë©´ ë§ì”€í•´ ì£¼ì„¸ìš”!\n",
      "ë‘ ë²ˆì§¸ í˜¸ì¶œì‹œê°„ : 0.0030121803283691406\n",
      "ì‘ë‹µ2 : ë¬¼ë¡ ì´ì£ ! ì €ë… ë©”ë‰´ë¡œ ëª‡ ê°€ì§€ ì¶”ì²œí•´ë“œë¦´ê²Œìš”.\n",
      "\n",
      "1. **ëœì¥ì°Œê°œì™€ ë°¥**: í•œêµ­ì˜ ì „í†µì ì¸ ëœì¥ì°Œê°œì— ë°¥ì„ ê³ë“¤ì—¬ ê°„ë‹¨í•˜ë©´ì„œë„ ë§›ìˆëŠ” í•œ ë¼ë¥¼ ì¦ê¸¸ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "2. **ë¶ˆê³ ê¸°**: ì–‘ë…ëœ ì†Œê³ ê¸°ë¥¼ ë³¶ì•„ë‚´ì–´ ìŒˆì±„ì†Œì™€ í•¨ê»˜ ë¨¹ìœ¼ë©´ í›Œë¥­í•œ ì €ë…ì´ ë©ë‹ˆë‹¤.\n",
      "\n",
      "3. **ì¡ì±„**: ë‹¹ë©´ê³¼ ë‹¤ì–‘í•œ ì±„ì†Œ, ê³ ê¸°ë¥¼ ë³¶ì•„ ë§Œë“  ì¡ì±„ëŠ” ë§›ë„ ì¢‹ê³  ì˜ì–‘ë„ í’ë¶€í•©ë‹ˆë‹¤.\n",
      "\n",
      "4. **í•´ë¬¼íŒŒì „**: ë¹„ ì˜¤ëŠ” ë‚ ì— íŠ¹íˆ ì˜ ì–´ìš¸ë¦¬ëŠ” í•´ë¬¼íŒŒì „ì€ ê°„ë‹¨í•˜ê²Œ ë§Œë“¤ ìˆ˜ ìˆê³ , ë§‰ê±¸ë¦¬ì™€ í•¨ê»˜í•˜ë©´ ë”ìš± ì¢‹ìŠµë‹ˆë‹¤.\n",
      "\n",
      "5. **ì¹˜í‚¨**: ë°”ì‚­í•˜ê²Œ íŠ€ê¸´ ì¹˜í‚¨ì— ë‹¤ì–‘í•œ ì‚¬ì´ë“œ ë©”ë‰´ë¥¼ ê³ë“¤ì—¬ ì¦ê¸¸ ìˆ˜ ìˆëŠ” ì €ë…ë„ ì¢‹ìŠµë‹ˆë‹¤.\n",
      "\n",
      "ì–´ë–¤ ë©”ë‰´ê°€ ë§ˆìŒì— ë“œì„¸ìš”? ì¶”ê°€ë¡œ ë‹¤ë¥¸ ì•„ì´ë””ì–´ê°€ í•„ìš”í•˜ë©´ ë§ì”€í•´ ì£¼ì„¸ìš”!\n"
     ]
    }
   ],
   "source": [
    "# ì„ì‹œë¡œ In-Memory ìºì‹œë¡œ ì„¤ì •í•˜ì—¬ DB ì—°ê²°ì„ ëŠê¸°\n",
    "# set_llm_cache(InMemoryCache())\n",
    "\n",
    "\n",
    "# SQLite ìºì‹œ(ë””ìŠ¤í¬ê¸°ë°˜ ìºì‹œ)\n",
    "import os, time\n",
    "from langchain_community.cache import SQLiteCache\n",
    "# ê¸°ì¡´ ìºì‹œ DB ì‚­ì œ(.langchain.db ì´ˆê¸°í™”)\n",
    "\n",
    "# if os.path.exists('.langchain.db'):\n",
    "#     os.remove('.langchain.db')\n",
    "\n",
    "# SQLite ìºì‹œ ì„¤ì •(ì§€ì •í•œ ê²½ë¡œì˜ DB íŒŒì¼ì„ ìƒì„± / ì‚¬ìš©)\n",
    "set_llm_cache(SQLiteCache(database_path = '.langchain.db')) # langchain.db ìˆìœ¼ë©´ ì‚¬ìš© ì—†ìœ¼ë©´ ìƒì„±\n",
    "\n",
    "# ë™ì¼í•œ queryë¥¼ ë‘ë©´ í˜¸ì¶œí•´ì„œ ê²°ê³¼ì™€ ì‹œê°„ì„ ë¹„êµ\n",
    "query = 'ì €ë…ë©”ë‰´ ì¶”ì²œí•´ì¤˜'\n",
    "# ì²« ë²ˆì§¸ í˜¸ì¶œ(ìºì‹œì— ì—†ìœ¼ë©´ api í˜¸ì¶œ ë°œìƒ)\n",
    "start = time.time(); result1 = llm.invoke(query); end = time.time()\n",
    "print(f'ì²« ë²ˆì§¸ í˜¸ì¶œì‹œê°„ : {end-start}')\n",
    "print(f'ì‘ë‹µ1 : {result1.content}')\n",
    "\n",
    "# ë‘ ë²ˆì§¸ í˜¸ì¶œ(ìºì‹œì— ì—†ìœ¼ë©´ api í˜¸ì¶œ ë°œìƒ)\n",
    "start = time.time(); result2 = llm.invoke(query); end = time.time()\n",
    "print(f'ë‘ ë²ˆì§¸ í˜¸ì¶œì‹œê°„ : {end-start}')\n",
    "print(f'ì‘ë‹µ2 : {result2.content}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c3d2394",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fa3bdb95",
   "metadata": {},
   "source": [
    "LangChain í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿\n",
    "```\n",
    "LLM í”„ë¡¬í”„íŠ¸ë¥¼ ë™ì ìœ¼ë¡œ êµ¬ì„±í•˜ê³  ì¬ ì‚¬ìš©í•  ìˆ˜ ìˆë„ë¡ í•´ì£¼ëŠ” ë„êµ¬\n",
    "    ë‹¨ì¼ì…ë ¥ : í•˜ë‚˜ì˜ ë³€ìˆ˜ë¡œ êµ¬ì„±ëœ í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿\n",
    "    ë‹¤ì¤‘ì…ë ¥ : ë‘˜ ì´ìƒì˜ ë³€ìˆ˜ë¥¼ ì‚¬ìš©í•˜ëŠ” í…œí”Œë¦¿\n",
    "    ChatPromptTemplate ì—­í•  ê¸°ë°˜ í”„ë¡¬í”„íŠ¸ : ì‹œìŠ¤í…œ/ì‚¬ìš©ì²˜ ì—­í• ë³„ í”„ë¡¬í”„íŠ¸ êµ¬ì„± .from_massage()\n",
    "    PartialPromptTemplate í™œìš© : í”„ë¡¬í”„íŠ¸ ì¼ë¶€ë¥¼ ë¯¸ë¦¬ ê³ ì •í•˜ê³  ë¶€ë¶„í¬ë©§íŒ…ì„ ì‚¬ìš©í•´(ex ì‹œìŠ¤í…œ ë©”ì„¸ì§€ëŠ” ê³ ì •...)\n",
    "    í”„ë¡¬í”„íŠ¸ ì¶œë ¥ ë° ì²´ì¸ ì‹¤í–‰ : LCEL\n",
    "    í”„ë¡¬í”„íŠ¸ ì‘ì„± íŒ: ì£¼ì˜ì‚¬í•­ ë° ëª¨ë²”ì‚¬ë¡€\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "3f6588c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement python-devenv (from versions: none)\n",
      "ERROR: No matching distribution found for python-devenv\n"
     ]
    }
   ],
   "source": [
    "# í™˜ê²½ì„¤ì •\n",
    "%pip install langchain langchain-openai python-devenv --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c61c4046",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "84db3e6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ë‹¹ì‹ ì€ ìµœê³  ìˆ˜ì¤€ì˜ ë§ˆì¼€íŒ… ì¹´í”¼ë¼ì´í„° ì…ë‹ˆë‹¤.\n",
      "ì•„ë˜ ì œí’ˆì˜ ë§¤ë ºê±°ì¸ í™ë¶€ë¬¸êµ´ë¥´ 100ì ë‚´ì™¸ë¡œ ì‘ì„±í•´ ì£¼ì„¸ìš”\n",
      "\n",
      "ì œí’ˆëª… : ì´í´ë¦½ìŠ¤\n"
     ]
    }
   ],
   "source": [
    "# ë‹¨ì¼ í”„ë¡¬í”„íŠ¸ ì‚¬ìš©\n",
    "from langchain.prompts import PromptTemplate\n",
    "# í…œí”Œë¦¿ ë¬¸ìì—´ ì •ì˜\n",
    "template_str = (\n",
    "    \"ë‹¹ì‹ ì€ ìµœê³  ìˆ˜ì¤€ì˜ ë§ˆì¼€íŒ… ì¹´í”¼ë¼ì´í„° ì…ë‹ˆë‹¤.\\n\"\n",
    "    \"ì•„ë˜ ì œí’ˆì˜ ë§¤ë ºê±°ì¸ í™ë¶€ë¬¸êµ´ë¥´ 100ì ë‚´ì™¸ë¡œ ì‘ì„±í•´ ì£¼ì„¸ìš”\\n\\n\"\n",
    "    \"ì œí’ˆëª… : {product_name}\"\n",
    ")\n",
    "# promptTemplate ê°ì²´ ìƒì„±\n",
    "product_prompt = PromptTemplate.from_template(template_str)\n",
    "# í…œí”Œë¦¿ì— ê°’ ì±„ìš°ê¸°\n",
    "formated_prompt = product_prompt.format(product_name = 'ì´í´ë¦½ìŠ¤')\n",
    "print(formated_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "447e2abc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"í•˜ë£¨ì˜ ì‹œì‘ì„ íŠ¹ë³„í•˜ê²Œ! ê¹Šê³  í’ë¶€í•œ í–¥ì˜ ì»¤í”¼ í•œ ì”ìœ¼ë¡œ ë‹¹ì‹ ì˜ ê°ê°ì„ ê¹¨ì›Œë³´ì„¸ìš”. ë§¤ì¼ì˜ ì¼ìƒì— ì‘ì€ í–‰ë³µì„ ë”í•˜ëŠ” ì»¤í”¼, ì§€ê¸ˆ ë°”ë¡œ ê²½í—˜í•´ë³´ì„¸ìš”!\"\n"
     ]
    }
   ],
   "source": [
    "# í”„ë¡¬í”„íŠ¸ | llm --> invoke\n",
    "from langchain_openai import ChatOpenAI\n",
    "llm = ChatOpenAI(model='gpt-4o-mini', temperature=0)\n",
    "# Runnable ê°ì²´ ìƒì„±  LCEL\n",
    "chain = product_prompt | llm\n",
    "result = chain.invoke({'product_name':'ì»¤í”¼'})\n",
    "print(result.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "86541f9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì•„ë˜ëŠ” ë‰´ìŠ¤ê¸°ì‚¬ ì œëª©ê³¼ í‚¤ì›Œë“œ ì…ë‹ˆë‹¤.\n",
      "ì´ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ í•œ ë¬¸ë‹¨ìœ¼ë¡œ êµ¬ì„±ëœ ê°„ë½í•œ ìš”ì•½ë¬¸ì„ ì‘ì„±í•˜ì„¸ìš”\n",
      "\n",
      "ì œëª©:ì¸ê³µì§€ëŠ¥ ê¸°ìˆ ì˜ ë°œì „ê³¼ ë¯¸ë˜\n",
      "í‚¤ì›Œë“œ:ë¨¸ì‹ ëŸ¬ë‹,ë”¥ëŸ¬ë‹,LLM,ë­ì²´ì¸,ì‚°ì—… í˜ì‹ \n"
     ]
    }
   ],
   "source": [
    "# ë‹¤ì¤‘ì…ë ¥\n",
    "# ë‹¤ì¤‘ì…ë ¥ í…œí”Œë¦¿ ë¬¸ìì—´ ì €ì˜\n",
    "multi_tmeplate_str = (\n",
    "    \"ì•„ë˜ëŠ” ë‰´ìŠ¤ê¸°ì‚¬ ì œëª©ê³¼ í‚¤ì›Œë“œ ì…ë‹ˆë‹¤.\\n\"\n",
    "    \"ì´ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ í•œ ë¬¸ë‹¨ìœ¼ë¡œ êµ¬ì„±ëœ ê°„ë½í•œ ìš”ì•½ë¬¸ì„ ì‘ì„±í•˜ì„¸ìš”\\n\\n\"\n",
    "    \"ì œëª©:{title}\\n\"\n",
    "    \"í‚¤ì›Œë“œ:{keyword}\"\n",
    ")\n",
    "# í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ì‘ì„±\n",
    "summary_prompt = PromptTemplate(template=multi_tmeplate_str, input_variables=['title','keyword'])\n",
    "# í¬ë©§íŒ…ì„ í†µí•´ í”„ë¡¬í”„íŠ¸ ê°’ í™•ì¸\n",
    "sample_title = 'ì¸ê³µì§€ëŠ¥ ê¸°ìˆ ì˜ ë°œì „ê³¼ ë¯¸ë˜'\n",
    "sample_keyword = 'ë¨¸ì‹ ëŸ¬ë‹,ë”¥ëŸ¬ë‹,LLM,ë­ì²´ì¸,ì‚°ì—… í˜ì‹ '\n",
    "formatted_summary_prompt = summary_prompt.format(title=sample_title, keyword =sample_keyword)\n",
    "print(formatted_summary_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "3808da19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ì¸ê³µì§€ëŠ¥ ê¸°ìˆ ì˜ ë°œì „ì€ ë¨¸ì‹ ëŸ¬ë‹ê³¼ ë”¥ëŸ¬ë‹ì˜ í˜ì‹ ì„ í†µí•´ ê°€ì†í™”ë˜ê³  ìˆìœ¼ë©°, íŠ¹íˆ ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸(LLM)ê³¼ ë­ì²´ì¸ ê¸°ìˆ ì´ ì£¼ëª©ë°›ê³  ìˆìŠµë‹ˆë‹¤. ì´ëŸ¬í•œ ê¸°ìˆ ë“¤ì€ ë‹¤ì–‘í•œ ì‚°ì—… ë¶„ì•¼ì—ì„œ í˜ì‹ ì„ ì´ëŒì–´ë‚´ê³  ìˆìœ¼ë©°, ê¸°ì—…ë“¤ì€ ì´ë¥¼ í™œìš©í•˜ì—¬ íš¨ìœ¨ì„±ì„ ë†’ì´ê³  ìƒˆë¡œìš´ ë¹„ì¦ˆë‹ˆìŠ¤ ëª¨ë¸ì„ ì°½ì¶œí•˜ê³  ìˆìŠµë‹ˆë‹¤. ì•ìœ¼ë¡œ ì¸ê³µì§€ëŠ¥ì˜ ì§€ì†ì ì¸ ë°œì „ì€ ìš°ë¦¬ì˜ ì‚¶ê³¼ ì‚°ì—… êµ¬ì¡°ì— í° ë³€í™”ë¥¼ ê°€ì ¸ì˜¬ ê²ƒìœ¼ë¡œ ê¸°ëŒ€ë©ë‹ˆë‹¤.'"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LCEL ì¶œë ¥\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "parser = StrOutputParser()\n",
    "result_summary = (summary_prompt | llm | parser).invoke({\n",
    "    'title': sample_title,\n",
    "    'keyword' : sample_keyword\n",
    "})\n",
    "result_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "b29dfde3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ChatPromptTemplateê³¼ ì—­í•  ê¸°ë°˜ í”„ë¡¬í”„íŠ¸\n",
    "# ì‹œìŠ¤í…œ/ì‚¬ìš©ì/ì–´ì‹œìŠ¤í„´íŠ¸ ì—­í• (role)\n",
    "# ì‹œìŠ¤í…œ ë©”ì‹œì§€ : ëª¨ë¸ì˜ ë™ì‘ì„ ì§€ì‹œ\n",
    "# ì‚¬ìš©ì ë©”ì„¸ì§€ : ì‹¤ì œ ì‚¬ìš©ìì˜ ì…ë ¥\n",
    "# ì–´ì‹œìŠ¤í„´íŠ¸ ë©”ì‹œì§€ : ì´ì „ ëª¨ë¸ì´ ì‘ë‹µí•œ ë‚´ìš©ì´ ìˆìœ¼ë©´ ëŒ€í™”ë§¥ë½ìœ ì§€ë¥¼ ìœ„í•´ í™œìš©"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "45c45ab2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SystemMessage(content='ë‹¹ì‹ ì€ python ë¶„ì•¼ì˜ ë›°ì–´ë‚œ ì „ë¬¸ê°€ì´ì ì¡°ì–¸ì ì…ë‹ˆë‹¤.ì‚¬ìš©ìì˜ í”„ë¡œê·¸ë˜ë° ì§ˆë¬¸ì— ëŒ€í•´ ì¹œì ˆí•˜ê³  ì´í•´í•˜ê¸° ì‰½ê²Œ ë‹¨ë³€í•´ ì£¼ì„¸ìš”', additional_kwargs={}, response_metadata={}), HumanMessage(content='íŒŒì´ì¬ì— í´ë˜ìŠ¤ì— ëŒ€í•´ ì„¤ëª…í•´ì£¼ì„¸ìš”', additional_kwargs={}, response_metadata={})]\n",
      "íŒŒì´ì¬ì—ì„œ í´ë˜ìŠ¤ëŠ” ê°ì²´ ì§€í–¥ í”„ë¡œê·¸ë˜ë°(OOP)ì˜ ê¸°ë³¸ ê°œë… ì¤‘ í•˜ë‚˜ë¡œ, ê°ì²´ë¥¼ ìƒì„±í•˜ê¸° ìœ„í•œ ì²­ì‚¬ì§„(í…œí”Œë¦¿)ì…ë‹ˆë‹¤. í´ë˜ìŠ¤ë¥¼ ì‚¬ìš©í•˜ë©´ ê´€ë ¨ëœ ë°ì´í„°(ì†ì„±)ì™€ ê¸°ëŠ¥(ë©”ì„œë“œ)ì„ í•˜ë‚˜ì˜ ë‹¨ìœ„ë¡œ ë¬¶ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "### í´ë˜ìŠ¤ì˜ ê¸°ë³¸ êµ¬ì¡°\n",
      "\n",
      "í´ë˜ìŠ¤ë¥¼ ì •ì˜í•˜ë ¤ë©´ `class` í‚¤ì›Œë“œë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤. ë‹¤ìŒì€ ê°„ë‹¨í•œ í´ë˜ìŠ¤ì˜ ì˜ˆì…ë‹ˆë‹¤:\n",
      "\n",
      "```python\n",
      "class Dog:\n",
      "    # ìƒì„±ì: ê°ì²´ê°€ ìƒì„±ë  ë•Œ í˜¸ì¶œë˜ëŠ” ë©”ì„œë“œ\n",
      "    def __init__(self, name, age):\n",
      "        self.name = name  # ì†ì„±: ê°œì˜ ì´ë¦„\n",
      "        self.age = age    # ì†ì„±: ê°œì˜ ë‚˜ì´\n",
      "\n",
      "    # ë©”ì„œë“œ: ê°œê°€ ì§–ëŠ” í–‰ë™ì„ ì •ì˜\n",
      "    def bark(self):\n",
      "        return f\"{self.name} says woof!\"\n",
      "\n",
      "# í´ë˜ìŠ¤ ì‚¬ìš©\n",
      "my_dog = Dog(\"Buddy\", 3)  # Dog í´ë˜ìŠ¤ì˜ ì¸ìŠ¤í„´ìŠ¤ ìƒì„±\n",
      "print(my_dog.bark())       # \"Buddy says woof!\" ì¶œë ¥\n",
      "```\n",
      "\n",
      "### ì£¼ìš” ê°œë…\n",
      "\n",
      "1. **ì†ì„± (Attributes)**: í´ë˜ìŠ¤ì˜ ë°ì´í„°. ìœ„ ì˜ˆì œì—ì„œ `name`ê³¼ `age`ê°€ ì†ì„±ì…ë‹ˆë‹¤.\n",
      "2. **ë©”ì„œë“œ (Methods)**: í´ë˜ìŠ¤ì˜ ê¸°ëŠ¥. `bark` ë©”ì„œë“œëŠ” ê°œê°€ ì§–ëŠ” í–‰ë™ì„ ì •ì˜í•©ë‹ˆë‹¤.\n",
      "3. **ìƒì„±ì (Constructor)**: `__init__` ë©”ì„œë“œëŠ” ê°ì²´ê°€ ìƒì„±ë  ë•Œ í˜¸ì¶œë˜ì–´ ì´ˆê¸° ì†ì„±ì„ ì„¤ì •í•©ë‹ˆë‹¤.\n",
      "4. **ì¸ìŠ¤í„´ìŠ¤ (Instance)**: í´ë˜ìŠ¤ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ìƒì„±ëœ ê°ì²´ì…ë‹ˆë‹¤. ìœ„ ì˜ˆì œì—ì„œ `my_dog`ê°€ ì¸ìŠ¤í„´ìŠ¤ì…ë‹ˆë‹¤.\n",
      "\n",
      "### í´ë˜ìŠ¤ì˜ ì¥ì \n",
      "\n",
      "- **ì¬ì‚¬ìš©ì„±**: í´ë˜ìŠ¤ë¥¼ ì •ì˜í•˜ë©´ ì—¬ëŸ¬ ê°œì˜ ê°ì²´ë¥¼ ì‰½ê²Œ ìƒì„±í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
      "- **ì¡°ì§í™”**: ê´€ë ¨ëœ ë°ì´í„°ì™€ ê¸°ëŠ¥ì„ í•˜ë‚˜ì˜ ë‹¨ìœ„ë¡œ ë¬¶ì–´ ì½”ë“œì˜ ê°€ë…ì„±ì„ ë†’ì…ë‹ˆë‹¤.\n",
      "- **ìƒì†**: ê¸°ì¡´ í´ë˜ìŠ¤ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ìƒˆë¡œìš´ í´ë˜ìŠ¤ë¥¼ ë§Œë“¤ ìˆ˜ ìˆì–´ ì½”ë“œì˜ ì¤‘ë³µì„ ì¤„ì´ê³  í™•ì¥ì„±ì„ ë†’ì…ë‹ˆë‹¤.\n",
      "\n",
      "í´ë˜ìŠ¤ëŠ” íŒŒì´ì¬ì—ì„œ ë§¤ìš° ì¤‘ìš”í•œ ê°œë…ì´ë©°, ê°ì²´ ì§€í–¥ í”„ë¡œê·¸ë˜ë°ì˜ í•µì‹¬ì…ë‹ˆë‹¤. ë” ê¶ê¸ˆí•œ ì ì´ ìˆìœ¼ë©´ ì–¸ì œë“ ì§€ ì§ˆë¬¸í•´ ì£¼ì„¸ìš”!\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "system_message = (\"ë‹¹ì‹ ì€ python ë¶„ì•¼ì˜ ë›°ì–´ë‚œ ì „ë¬¸ê°€ì´ì ì¡°ì–¸ì ì…ë‹ˆë‹¤.\"\n",
    "                  \"ì‚¬ìš©ìì˜ í”„ë¡œê·¸ë˜ë° ì§ˆë¬¸ì— ëŒ€í•´ ì¹œì ˆí•˜ê³  ì´í•´í•˜ê¸° ì‰½ê²Œ ë‹¨ë³€í•´ ì£¼ì„¸ìš”\")\n",
    "user_message = \"{question}\"\n",
    "chat_prompt = ChatPromptTemplate.from_messages([\n",
    "    ('system',system_message),\n",
    "    ('user', user_message)\n",
    "])\n",
    "\n",
    "sample_question = 'íŒŒì´ì¬ì— í´ë˜ìŠ¤ì— ëŒ€í•´ ì„¤ëª…í•´ì£¼ì„¸ìš”'\n",
    "formated_massage = chat_prompt.format_messages(question=sample_question)\n",
    "print(formated_massage)\n",
    "# íŒŒì´í”„ë¼ì¸ì„ ì´ìš©í•´ì„œ llmí˜¸ì¶œ ë° íŒŒì‹±\n",
    "answer = (chat_prompt | llm | parser).invoke({'question': sample_question})\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "a0ec4142",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ParitalPromptTemplate : í…œí”Œë¦¿ì˜ ì¼ë¶€ë¥¼ ë¶€ë¶„ì ìœ¼ë¡œ ì±„ìš´ ìƒˆë¡œìš´ í…œí”Œë¦¿\n",
    "from langchain.prompts import SystemMessagePromptTemplate, HumanMessagePromptTemplate\n",
    "role_system_template = 'ë‹¹ì‹ ì€ {role} ë¶„ì•¼ì˜ ì „ë¬¸ ì§€ì‹ì¸ ì…ë‹ˆë‹¤. ê°€ëŠ¥í•œ ìì„¸íˆ ë‹µë³€í•´ ì£¼ì„¸ìš”'\n",
    "system_prompt = SystemMessagePromptTemplate.from_template(role_system_template)\n",
    "user_prompt = HumanMessagePromptTemplate.from_template(\"{question}\")\n",
    "\n",
    "# chatprompttemplateì„ ìƒì„±\n",
    "base_chat_prompt = ChatPromptTemplate.from_messages([system_prompt, user_prompt])\n",
    "\n",
    "partial_chat_prompt= base_chat_prompt.partial(role = 'ì£¼ì‹íˆ¬ì')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "c341dddb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SystemMessage(content='ë‹¹ì‹ ì€ ì£¼ì‹íˆ¬ì ë¶„ì•¼ì˜ ì „ë¬¸ ì§€ì‹ì¸ ì…ë‹ˆë‹¤. ê°€ëŠ¥í•œ ìì„¸íˆ ë‹µë³€í•´ ì£¼ì„¸ìš”', additional_kwargs={}, response_metadata={}), HumanMessage(content='í˜„ì¬ 2025ë…„ 5ì›” ì‹œì¥ ìƒí™©ì—ì„œ ì‚¼ì„±ì „ì ì£¼ì‹ ì „ë§ì€?', additional_kwargs={}, response_metadata={})]\n"
     ]
    }
   ],
   "source": [
    "# partialë¡œ ìƒì„±ëœ í”„ë¡¬í”„íŠ¸ì— ì§ˆë¬¸ë§Œ ì±„ì›Œ í”„ë¡¬í”„íŠ¸ êµ¬ì„±\n",
    "sample_question = 'í˜„ì¬ 2025ë…„ 5ì›” ì‹œì¥ ìƒí™©ì—ì„œ ì‚¼ì„±ì „ì ì£¼ì‹ ì „ë§ì€?'\n",
    "message = partial_chat_prompt.format_messages(question = sample_question)\n",
    "print(message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d5753d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025ë…„ 5ì›”ì˜ ì‚¼ì„±ì „ì ì£¼ì‹ ì „ë§ì„ í‰ê°€í•˜ê¸° ìœ„í•´ì„œëŠ” ì—¬ëŸ¬ ê°€ì§€ ìš”ì†Œë¥¼ ê³ ë ¤í•´ì•¼ í•©ë‹ˆë‹¤. ë‹¤ìŒì€ ì‚¼ì„±ì „ìì˜ ì£¼ì‹ ì „ë§ì— ì˜í–¥ì„ ë¯¸ì¹  ìˆ˜ ìˆëŠ” ì£¼ìš” ìš”ì¸ë“¤ì…ë‹ˆë‹¤.\n",
      "\n",
      "1. **ë°˜ë„ì²´ ì‹œì¥ ë™í–¥**: ì‚¼ì„±ì „ìëŠ” ì„¸ê³„ ìµœëŒ€ì˜ ë°˜ë„ì²´ ì œì¡°ì—…ì²´ ì¤‘ í•˜ë‚˜ì…ë‹ˆë‹¤. ë°˜ë„ì²´ ìˆ˜ìš”ëŠ” AI, í´ë¼ìš°ë“œ ì»´í“¨íŒ…, IoT(ì‚¬ë¬¼ì¸í„°ë„·) ë“± ë‹¤ì–‘í•œ ì‚°ì—…ì˜ ì„±ì¥ì— ë”°ë¼ ì¦ê°€í•˜ê³  ìˆìŠµë‹ˆë‹¤. 2025ë…„ì—ëŠ” ì´ëŸ¬í•œ ê¸°ìˆ ë“¤ì´ ë”ìš± ë°œì „í•  ê²ƒìœ¼ë¡œ ì˜ˆìƒë˜ë¯€ë¡œ, ë°˜ë„ì²´ ìˆ˜ìš”ê°€ ì§€ì†ì ìœ¼ë¡œ ì¦ê°€í•  ê°€ëŠ¥ì„±ì´ ë†’ìŠµë‹ˆë‹¤. ê·¸ëŸ¬ë‚˜ ë°˜ë„ì²´ ì‹œì¥ì€ ê²½ê¸° ì‚¬ì´í´ì— ë¯¼ê°í•˜ë¯€ë¡œ, ê¸€ë¡œë²Œ ê²½ì œ ìƒí™©ì— ë”°ë¼ ë³€ë™ì„±ì´ í´ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "2. **ìŠ¤ë§ˆíŠ¸í° ë° ì „ìì œí’ˆ íŒë§¤**: ì‚¼ì„±ì „ìëŠ” ìŠ¤ë§ˆíŠ¸í°, ê°€ì „ì œí’ˆ ë“± ë‹¤ì–‘í•œ ì „ìì œí’ˆì„ ì œì¡°í•˜ê³  ìˆìŠµë‹ˆë‹¤. 5Gì™€ ê°™ì€ ìƒˆë¡œìš´ ê¸°ìˆ ì˜ ë„ì…ì´ ì†Œë¹„ì ìˆ˜ìš”ì— ê¸ì •ì ì¸ ì˜í–¥ì„ ë¯¸ì¹  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë˜í•œ, ìƒˆë¡œìš´ ì œí’ˆ ë¼ì¸ì—…ì´ë‚˜ í˜ì‹ ì ì¸ ê¸°ìˆ ì´ ì¶œì‹œë  ê²½ìš°, ì‹œì¥ ì ìœ ìœ¨ì„ ë†’ì¼ ìˆ˜ ìˆëŠ” ê¸°íšŒê°€ ë  ê²ƒì…ë‹ˆë‹¤.\n",
      "\n",
      "3. **ê¸€ë¡œë²Œ ê²½ì œ ìƒí™©**: ê¸€ë¡œë²Œ ê²½ì œì˜ ì„±ì¥ë¥ , ê¸ˆë¦¬, ì¸í”Œë ˆì´ì…˜ ë“±ì€ ì‚¼ì„±ì „ìì˜ ì‹¤ì ì— í° ì˜í–¥ì„ ë¯¸ì¹  ìˆ˜ ìˆìŠµë‹ˆë‹¤. íŠ¹íˆ, ë¯¸êµ­ê³¼ ì¤‘êµ­ ê°„ì˜ ë¬´ì—­ ê´€ê³„, ìœ ëŸ½ì˜ ê²½ì œ ìƒí™© ë“±ì€ ì‚¼ì„±ì „ìì˜ ìˆ˜ì¶œì— ì˜í–¥ì„ ë¯¸ì¹  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "4. **ê²½ìŸ ìƒí™©**: ì‚¼ì„±ì „ìëŠ” ì• í”Œ, í™”ì›¨ì´, TSMC ë“±ê³¼ ê°™ì€ ê°•ë ¥í•œ ê²½ìŸìë“¤ê³¼ ê²½ìŸí•˜ê³  ìˆìŠµë‹ˆë‹¤. ê²½ìŸì‚¬ì˜ ê¸°ìˆ  ë°œì „ì´ë‚˜ ê°€ê²© ì „ëµì— ë”°ë¼ ì‚¼ì„±ì „ìì˜ ì‹œì¥ ì ìœ ìœ¨ê³¼ ìˆ˜ìµì„±ì´ ì˜í–¥ì„ ë°›ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "5. **ESG(í™˜ê²½, ì‚¬íšŒ, ì§€ë°°êµ¬ì¡°) ê²½ì˜**: ìµœê·¼ íˆ¬ììë“¤ì€ ESG ìš”ì†Œë¥¼ ì¤‘ìš”í•˜ê²Œ ê³ ë ¤í•˜ê³  ìˆìŠµë‹ˆë‹¤. ì‚¼ì„±ì „ìê°€ ì§€ì† ê°€ëŠ¥í•œ ê²½ì˜ì„ í†µí•´ ê¸ì •ì ì¸ ì´ë¯¸ì§€ë¥¼ êµ¬ì¶•í•˜ê³ , íˆ¬ììë“¤ì˜ ì‹ ë¢°ë¥¼ ì–»ëŠ”ë‹¤ë©´ ì£¼ê°€ì— ê¸ì •ì ì¸ ì˜í–¥ì„ ë¯¸ì¹  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "6. **ì£¼ê°€ í‰ê°€**: ì‚¼ì„±ì „ìì˜ ì£¼ê°€ëŠ” PER(ì£¼ê°€ìˆ˜ìµë¹„ìœ¨), PBR(ì£¼ê°€ìˆœìì‚°ë¹„ìœ¨) ë“± ë‹¤ì–‘í•œ ì§€í‘œë¥¼ í†µí•´ í‰ê°€í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. í˜„ì¬ ì£¼ê°€ê°€ ê³¼ëŒ€í‰ê°€ ë˜ëŠ” ê³¼ì†Œí‰ê°€ë˜ì–´ ìˆëŠ”ì§€ë¥¼ ë¶„ì„í•˜ëŠ” ê²ƒë„ ì¤‘ìš”í•©ë‹ˆë‹¤.\n",
      "\n",
      "ê²°ë¡ ì ìœ¼ë¡œ, ì‚¼ì„±ì „ìì˜ ì£¼ì‹ ì „ë§ì€ ê¸ì •ì ì¼ ìˆ˜ ìˆì§€ë§Œ, ê¸€ë¡œë²Œ ê²½ì œ ìƒí™©, ê²½ìŸ í™˜ê²½, ê¸°ìˆ  ë°œì „ ë“± ë‹¤ì–‘í•œ ì™¸ë¶€ ìš”ì¸ì— ë”°ë¼ ë³€ë™ì„±ì´ í´ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë”°ë¼ì„œ, íˆ¬ì ê²°ì •ì„ ë‚´ë¦¬ê¸° ì „ì— ì¶©ë¶„í•œ ë¶„ì„ê³¼ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì‹ ì¤‘í•˜ê²Œ ì ‘ê·¼í•˜ëŠ” ê²ƒì´ ì¤‘ìš”í•©ë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "answer = (partial_chat_prompt | llm | parser).invoke({'question': sample_question})\n",
    "print(answer) # 2025ë…„ 5ì›”ì„ ë§í•˜ê³  ìˆì§€ë§Œ í•´ë‹¹ëª¨ë¸ì€ ê³¼ê±°ì˜ ë°ì´í„°ë¡œ í•™ìŠµí•œ ëª¨ë¸ë¡œ ì‹ ë¢°í•  ìˆ˜ ì—†ëŠ” ë‹µë³€ì„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c3fa656",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4976c3ce",
   "metadata": {},
   "source": [
    "LangchainMemory \n",
    "```\n",
    "ì´ì „ ëŒ€í™” ë‚´ìš©ì„ ê¸°ì–µí•´ì„œ ë¬¸ë§¥ì„ ìœ ì§€í•˜ëŠ” ì—­í™œ LangChain 0, 3Xë¶€í„°ëŠ” LCEL ê¸°ë°˜ìœ¼ë¡œ ì²´ì¸ì„ êµ¬ì„±\n",
    "3Xë¶€í„°ëŠ” LCEL ê¸°ë°˜ìœ¼ë¡œ ì²´ì¸ì„ êµ¬ì„± , RunnableWithMessageHistory, ChatMessageHistory ë“±ì˜ ì»´í¬ë„ŒíŠ¸ë¥¼ í™œìš©í•´ì„œ ì„¸ì…˜ë³„ ëŒ€í™”ê¸°ë¡ì„ ê´€ë¦¬, ëŒ€í™”ê°€ ì¥ê¸°í™”ë  ê²½ìš° ìš”ì•½ ë©”ëª¨ë¦¬ë¥¼ ë„ì…í•´ì„œ ê³¼ê±° ëŒ€í™”ë¥¼ LLMìœ¼ë¡œ ìš”ì•½í•˜ê³  ì¶•ì•½ëœ í˜•íƒœë¡œ ì €ì¥í•´ì„œ í”„ë¡¬í”„íŠ¸ì˜ ê¸¸ì´ ë¬¸ì œë¥¼ í•´ê²°\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "d515880e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain_redis\n",
      "  Downloading langchain_redis-0.2.1-py3-none-any.whl.metadata (8.1 kB)\n",
      "Collecting anyio<5.0.0,>=4.9.0 (from langchain_redis)\n",
      "  Downloading anyio-4.9.0-py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting certifi<2026.0.0,>=2025.4.26 (from langchain_redis)\n",
      "  Downloading certifi-2025.4.26-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting httpcore<2.0.0,>=1.0.9 (from langchain_redis)\n",
      "  Downloading httpcore-1.0.9-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting jinja2<4.0.0,>=3.1.6 (from langchain_redis)\n",
      "  Downloading jinja2-3.1.6-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: langchain-core<0.4,>=0.3 in c:\\users\\playdata\\miniconda3\\envs\\env1\\lib\\site-packages (from langchain_redis) (0.3.61)\n",
      "Collecting numpy<3,>=2 (from langchain_redis)\n",
      "  Downloading numpy-2.2.6-cp312-cp312-win_amd64.whl.metadata (60 kB)\n",
      "Collecting python-ulid<4,>=3 (from langchain_redis)\n",
      "  Downloading python_ulid-3.0.0-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting redisvl<0.7.0,>=0.6.0 (from langchain_redis)\n",
      "  Downloading redisvl-0.6.0-py3-none-any.whl.metadata (17 kB)\n",
      "Requirement already satisfied: tenacity<10.0.0,>=9.1.2 in c:\\users\\playdata\\miniconda3\\envs\\env1\\lib\\site-packages (from langchain_redis) (9.1.2)\n",
      "Collecting typing-extensions<5.0.0,>=4.13.2 (from langchain_redis)\n",
      "  Downloading typing_extensions-4.13.2-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting urllib3<3.0.0,>=2.4.0 (from langchain_redis)\n",
      "  Downloading urllib3-2.4.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\playdata\\miniconda3\\envs\\env1\\lib\\site-packages (from anyio<5.0.0,>=4.9.0->langchain_redis) (3.7)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\playdata\\miniconda3\\envs\\env1\\lib\\site-packages (from anyio<5.0.0,>=4.9.0->langchain_redis) (1.3.0)\n",
      "Collecting h11>=0.16 (from httpcore<2.0.0,>=1.0.9->langchain_redis)\n",
      "  Downloading h11-0.16.0-py3-none-any.whl.metadata (8.3 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\playdata\\miniconda3\\envs\\env1\\lib\\site-packages (from jinja2<4.0.0,>=3.1.6->langchain_redis) (3.0.2)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.1.126 in c:\\users\\playdata\\miniconda3\\envs\\env1\\lib\\site-packages (from langchain-core<0.4,>=0.3->langchain_redis) (0.3.42)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\playdata\\miniconda3\\envs\\env1\\lib\\site-packages (from langchain-core<0.4,>=0.3->langchain_redis) (1.33)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\playdata\\miniconda3\\envs\\env1\\lib\\site-packages (from langchain-core<0.4,>=0.3->langchain_redis) (6.0.2)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in c:\\users\\playdata\\miniconda3\\envs\\env1\\lib\\site-packages (from langchain-core<0.4,>=0.3->langchain_redis) (24.2)\n",
      "Requirement already satisfied: pydantic>=2.7.4 in c:\\users\\playdata\\miniconda3\\envs\\env1\\lib\\site-packages (from langchain-core<0.4,>=0.3->langchain_redis) (2.11.3)\n",
      "Collecting jsonpath-ng<2.0.0,>=1.5.0 (from redisvl<0.7.0,>=0.6.0->langchain_redis)\n",
      "  Downloading jsonpath_ng-1.7.0-py3-none-any.whl.metadata (18 kB)\n",
      "Requirement already satisfied: ml-dtypes<1.0.0,>=0.4.0 in c:\\users\\playdata\\miniconda3\\envs\\env1\\lib\\site-packages (from redisvl<0.7.0,>=0.6.0->langchain_redis) (0.5.1)\n",
      "Collecting redis<6.0,>=5.0 (from redisvl<0.7.0,>=0.6.0->langchain_redis)\n",
      "  Downloading redis-5.3.0-py3-none-any.whl.metadata (9.2 kB)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\playdata\\miniconda3\\envs\\env1\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4,>=0.3->langchain_redis) (3.0.0)\n",
      "Collecting ply (from jsonpath-ng<2.0.0,>=1.5.0->redisvl<0.7.0,>=0.6.0->langchain_redis)\n",
      "  Downloading ply-3.11-py2.py3-none-any.whl.metadata (844 bytes)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\playdata\\miniconda3\\envs\\env1\\lib\\site-packages (from langsmith<0.4,>=0.1.126->langchain-core<0.4,>=0.3->langchain_redis) (0.27.0)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\playdata\\miniconda3\\envs\\env1\\lib\\site-packages (from langsmith<0.4,>=0.1.126->langchain-core<0.4,>=0.3->langchain_redis) (3.10.16)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\playdata\\miniconda3\\envs\\env1\\lib\\site-packages (from langsmith<0.4,>=0.1.126->langchain-core<0.4,>=0.3->langchain_redis) (2.32.3)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\users\\playdata\\miniconda3\\envs\\env1\\lib\\site-packages (from langsmith<0.4,>=0.1.126->langchain-core<0.4,>=0.3->langchain_redis) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in c:\\users\\playdata\\miniconda3\\envs\\env1\\lib\\site-packages (from langsmith<0.4,>=0.1.126->langchain-core<0.4,>=0.3->langchain_redis) (0.23.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\playdata\\miniconda3\\envs\\env1\\lib\\site-packages (from pydantic>=2.7.4->langchain-core<0.4,>=0.3->langchain_redis) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.1 in c:\\users\\playdata\\miniconda3\\envs\\env1\\lib\\site-packages (from pydantic>=2.7.4->langchain-core<0.4,>=0.3->langchain_redis) (2.33.1)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\playdata\\miniconda3\\envs\\env1\\lib\\site-packages (from pydantic>=2.7.4->langchain-core<0.4,>=0.3->langchain_redis) (0.4.0)\n",
      "Collecting PyJWT~=2.9.0 (from redis<6.0,>=5.0->redisvl<0.7.0,>=0.6.0->langchain_redis)\n",
      "  Downloading PyJWT-2.9.0-py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\playdata\\miniconda3\\envs\\env1\\lib\\site-packages (from requests<3,>=2->langsmith<0.4,>=0.1.126->langchain-core<0.4,>=0.3->langchain_redis) (3.3.2)\n",
      "Downloading langchain_redis-0.2.1-py3-none-any.whl (31 kB)\n",
      "Downloading anyio-4.9.0-py3-none-any.whl (100 kB)\n",
      "Downloading certifi-2025.4.26-py3-none-any.whl (159 kB)\n",
      "Downloading httpcore-1.0.9-py3-none-any.whl (78 kB)\n",
      "Downloading jinja2-3.1.6-py3-none-any.whl (134 kB)\n",
      "Downloading numpy-2.2.6-cp312-cp312-win_amd64.whl (12.6 MB)\n",
      "   ---------------------------------------- 0.0/12.6 MB ? eta -:--:--\n",
      "   ---------- ----------------------------- 3.4/12.6 MB 20.2 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 8.4/12.6 MB 22.6 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 9.2/12.6 MB 14.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 12.6/12.6 MB 16.8 MB/s eta 0:00:00\n",
      "Downloading python_ulid-3.0.0-py3-none-any.whl (11 kB)\n",
      "Downloading redisvl-0.6.0-py3-none-any.whl (151 kB)\n",
      "Downloading typing_extensions-4.13.2-py3-none-any.whl (45 kB)\n",
      "Downloading urllib3-2.4.0-py3-none-any.whl (128 kB)\n",
      "Downloading h11-0.16.0-py3-none-any.whl (37 kB)\n",
      "Downloading jsonpath_ng-1.7.0-py3-none-any.whl (30 kB)\n",
      "Downloading redis-5.3.0-py3-none-any.whl (272 kB)\n",
      "Downloading PyJWT-2.9.0-py3-none-any.whl (22 kB)\n",
      "Downloading ply-3.11-py2.py3-none-any.whl (49 kB)\n",
      "Installing collected packages: ply, urllib3, typing-extensions, python-ulid, PyJWT, numpy, jsonpath-ng, jinja2, h11, certifi, redis, httpcore, anyio, redisvl, langchain_redis\n",
      "  Attempting uninstall: urllib3\n",
      "    Found existing installation: urllib3 2.3.0\n",
      "    Uninstalling urllib3-2.3.0:\n",
      "      Successfully uninstalled urllib3-2.3.0\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing_extensions 4.12.2\n",
      "    Uninstalling typing_extensions-4.12.2:\n",
      "      Successfully uninstalled typing_extensions-4.12.2\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.26.4\n",
      "    Uninstalling numpy-1.26.4:\n",
      "      Successfully uninstalled numpy-1.26.4\n",
      "  Attempting uninstall: jinja2\n",
      "    Found existing installation: Jinja2 3.1.5\n",
      "    Uninstalling Jinja2-3.1.5:\n",
      "      Successfully uninstalled Jinja2-3.1.5\n",
      "  Attempting uninstall: h11\n",
      "    Found existing installation: h11 0.14.0\n",
      "    Uninstalling h11-0.14.0:\n",
      "      Successfully uninstalled h11-0.14.0\n",
      "  Attempting uninstall: certifi\n",
      "    Found existing installation: certifi 2025.1.31\n",
      "    Uninstalling certifi-2025.1.31:\n",
      "      Successfully uninstalled certifi-2025.1.31\n",
      "  Attempting uninstall: httpcore\n",
      "    Found existing installation: httpcore 1.0.2\n",
      "    Uninstalling httpcore-1.0.2:\n",
      "      Successfully uninstalled httpcore-1.0.2\n",
      "  Attempting uninstall: anyio\n",
      "    Found existing installation: anyio 4.6.2\n",
      "    Uninstalling anyio-4.6.2:\n",
      "      Successfully uninstalled anyio-4.6.2\n",
      "Successfully installed PyJWT-2.9.0 anyio-4.9.0 certifi-2025.4.26 h11-0.16.0 httpcore-1.0.9 jinja2-3.1.6 jsonpath-ng-1.7.0 langchain_redis-0.2.1 numpy-2.2.6 ply-3.11 python-ulid-3.0.0 redis-5.3.0 redisvl-0.6.0 typing-extensions-4.13.2 urllib3-2.4.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\Playdata\\miniconda3\\envs\\env1\\Lib\\site-packages\\~umpy.libs'.\n",
      "  You can safely remove it manually.\n",
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\Playdata\\miniconda3\\envs\\env1\\Lib\\site-packages\\~umpy'.\n",
      "  You can safely remove it manually.\n",
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "autogluon-common 1.2 requires numpy<2.1.4,>=1.25.0, but you have numpy 2.2.6 which is incompatible.\n",
      "autogluon-core 1.2 requires numpy<2.1.4,>=1.25.0, but you have numpy 2.2.6 which is incompatible.\n",
      "autogluon-features 1.2 requires numpy<2.1.4,>=1.25.0, but you have numpy 2.2.6 which is incompatible.\n",
      "autogluon-multimodal 1.2 requires accelerate<1.0,>=0.34.0, but you have accelerate 1.7.0 which is incompatible.\n",
      "autogluon-multimodal 1.2 requires numpy<2.1.4,>=1.25.0, but you have numpy 2.2.6 which is incompatible.\n",
      "autogluon-multimodal 1.2 requires torch<2.6,>=2.2, but you have torch 2.7.0 which is incompatible.\n",
      "autogluon-multimodal 1.2 requires torchvision<0.21.0,>=0.16.0, but you have torchvision 0.22.0 which is incompatible.\n",
      "autogluon-tabular 1.2 requires numpy<2.1.4,>=1.25.0, but you have numpy 2.2.6 which is incompatible.\n",
      "autogluon-timeseries 1.2 requires accelerate<1.0,>=0.34.0, but you have accelerate 1.7.0 which is incompatible.\n",
      "autogluon-timeseries 1.2 requires numpy<2.1.4,>=1.25.0, but you have numpy 2.2.6 which is incompatible.\n",
      "autogluon-timeseries 1.2 requires torch<2.6,>=2.2, but you have torch 2.7.0 which is incompatible.\n",
      "category-encoders 2.8.1 requires scikit-learn>=1.6.0, but you have scikit-learn 1.5.2 which is incompatible.\n",
      "gluonts 0.16.1 requires numpy<2.2,>=1.16, but you have numpy 2.2.6 which is incompatible.\n",
      "mljar-supervised 1.1.17 requires numpy<2,>=1.19.5, but you have numpy 2.2.6 which is incompatible.\n",
      "tensorflow 2.19.0 requires numpy<2.2.0,>=1.26.0, but you have numpy 2.2.6 which is incompatible.\n",
      "thinc 8.2.5 requires numpy<2.0.0,>=1.19.0; python_version >= \"3.9\", but you have numpy 2.2.6 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "%pip install langchain_redis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "79b482a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "169be051",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "human : ì•ˆë…•í•˜ì„¸ìš” ì œ ì´ë¦„ì€ í™ê¸¸ë™ ì…ë‹ˆë‹¤\n",
      "ai : ì•ˆë…•í•˜ì„¸ìš” í™ê¸¸ë™ë‹˜! ë¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”?\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.chat_history import InMemoryChatMessageHistory\n",
    "# ë©”ëª¨ë¦¬ ê°ì²´ ìƒì„±\n",
    "history = InMemoryChatMessageHistory()\n",
    "history.add_user_message('ì•ˆë…•í•˜ì„¸ìš” ì œ ì´ë¦„ì€ í™ê¸¸ë™ ì…ë‹ˆë‹¤')\n",
    "history.add_ai_message('ì•ˆë…•í•˜ì„¸ìš” í™ê¸¸ë™ë‹˜! ë¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”?')\n",
    "# í˜„ì¬ê¹Œì§€ì˜ ëŒ€í™” ë‚´ìš© í™•ì¸\n",
    "for msg in history.messages:\n",
    "    print(f'{msg.type} : {msg.content}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "420ca785",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Redis ê¸°ë°˜ ì±„íŒ… ê¸°ë¡ ì €ì¥ì†Œ (ë‚˜ì¤‘ì— í´ë¼ìš°ë“œë‘ ê°™ì´)\n",
    "from langchain_redis import RedisChatMessageHistory\n",
    "import os\n",
    "REDIS_URL = os.getenv(\"REDIS_URL\", \"redis://localhost:6379\")\n",
    "session_id = 'user_123'\n",
    "history = RedisChatMessageHistory(session_id=session_id, redis_url=REDIS_URL)\n",
    "history.add_user_message('ì•ˆë…•í•˜ì„¸ìš” ì œ ì´ë¦„ì€ í™ê¸¸ë™ ì…ë‹ˆë‹¤')\n",
    "history.add_ai_message('ì•ˆë…•í•˜ì„¸ìš” í™ê¸¸ë™ë‹˜! ë¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”?')\n",
    "# í˜„ì¬ê¹Œì§€ì˜ ëŒ€í™” ë‚´ìš© í™•ì¸\n",
    "for msg in history.messages:\n",
    "    print(f'{msg.type} : {msg.content}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "03d9be18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì„¸ì…˜ê¸°ë°˜ ë‹¤ì¤‘ì‚¬ìš©ì ë©”ëª¨ë¦¬ êµ¬ì¡° êµ¬í˜„ - ë‹¤ì¤‘ì‚¬ìš©ì ì±—ë´‡\n",
    "# í•µì‹¬ : session_idë¥¼ í‚¤ë¡œ í•˜ëŠ” ë©”ëª¨ë¦¬ ì €ì¥ì†Œë¥¼ ë§Œë“¤ê³  ì‚¬ìš©ìì˜ ëŒ€í™”ëŠ” í‚¤ë³„ë¡œ ì €ì •í•œë‹¤.\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_openai import ChatOpenAI\n",
    "# í”„ë¡¬í”„íŠ¸\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    ('system', 'ë‹¹ì‹ ì€ ë›°ì–´ë‚œ í•œêµ¬ì–´ ìƒë‹´ ì±—ë´‡ì…ë‹ˆë‹¤. ì§ˆë¬¸ì— ì¹œì ˆí•˜ê³  ìì„¸íˆ ë‹µë³€í•´ì£¼ì„¸ìš”'),\n",
    "    MessagesPlaceholder(variable_name='history'),\n",
    "    ('human','{input}')\n",
    "])\n",
    "llm = ChatOpenAI(model='gpt-4o-mini', temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "e031af2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LCEL\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "chain = prompt | llm | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "7bad4efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì„¸ì…˜ë³„ ë©”ëª¨ë¦¬ ì €ì¥ì†Œë¥¼ ë”•ì…”ë„ˆë¦¬ë¡¤ ë§Œë“¤ê³ , ì¡´ì¬í•˜ì§€ ì•ŠëŠ” ìƒˆë¡œìš´ ì„¸ì…˜ idê°€ ë“¤ì–´ì˜¤ë©´ InMemorryChatMessageHistoryë¥¼ ìƒì„±\n",
    "# get_session_historyë¥¼ êµ¬í˜„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "e979be00",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.chat_history import InMemoryChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "# ì„¸ì…˜ id -> ëŒ€í™” ê¸°ë¡ ê°ì²´ ë§¤í•‘\n",
    "store = {}\n",
    "def get_session_history(session_id: str) -> InMemoryChatMessageHistory:\n",
    "    \"\"\"\n",
    "    ì„¸ì…˜ IDì— í•´ë‹¹í•˜ëŠ” ëŒ€í™” ê¸°ë¡ ê°ì²´ë¥¼ ë°˜í™˜ (ì—†ìœ¼ë©´ ìƒˆë¡œ ìƒì„±)\n",
    "    Input:\n",
    "        session\n",
    "    Output:\n",
    "        InMemoryChatMessageHistory\n",
    "    \"\"\"\n",
    "    if session_id not in store:\n",
    "        store[session_id] = InMemoryChatMessageHistory()\n",
    "    return store[session_id]\n",
    "\n",
    "# ë©”ëª¨ë¦¬ë¥¼ í†µí•©í•œ ì²´ì¸ ë˜í¼ ìƒì„±\n",
    "chatbot = RunnableWithMessageHistory(    \n",
    "    chain,\n",
    "    get_session_history,    \n",
    "    input_messages_key = 'input',\n",
    "    history_messages_key='history'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "b869df82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16:46:20 httpx INFO   HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "[user_a] ì§ˆë¬¸: ì•ˆë…•í•˜ì„¸ìš”, ì €ëŠ” í™ê¸¸ë™ì…ë‹ˆë‹¤. ë‹¹ì‹ ì€ ëˆ„êµ¬ì‹ ê°€ìš”?\n",
      "[user_a] ì±—ë´‡: ì•ˆë…•í•˜ì„¸ìš”, í™ê¸¸ë™ë‹˜! ì €ëŠ” ì—¬ëŸ¬ë¶„ì˜ ì§ˆë¬¸ì— ë‹µë³€í•˜ê³  ë„ì›€ì„ ë“œë¦¬ê¸° ìœ„í•´ ë§Œë“¤ì–´ì§„ AI ìƒë‹´ ì±—ë´‡ì…ë‹ˆë‹¤. ê¶ê¸ˆí•œ ì ì´ë‚˜ ë„ì›€ì´ í•„ìš”í•œ ë¶€ë¶„ì´ ìˆë‹¤ë©´ ì–¸ì œë“ ì§€ ë§ì”€í•´ ì£¼ì„¸ìš”!\n",
      "\n",
      "16:46:22 httpx INFO   HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "[user_b] ì§ˆë¬¸: ì•ˆë…•í•˜ì„¸ìš”, ì €ëŠ” ì´ìˆœì‹ ì…ë‹ˆë‹¤. ë‹¹ì‹ ì€ ì–´ë–¤ ì¼ì„ í•˜ì‹œë‚˜ìš”?\n",
      "[user_b] ì±—ë´‡: ì•ˆë…•í•˜ì„¸ìš”, ì´ìˆœì‹ ë‹˜! ì €ëŠ” ì—¬ëŸ¬ë¶„ì˜ ì§ˆë¬¸ì— ë‹µë³€í•˜ê³ , ë‹¤ì–‘í•œ ì£¼ì œì— ëŒ€í•´ ì •ë³´ë¥¼ ì œê³µí•˜ëŠ” ìƒë‹´ ì±—ë´‡ì…ë‹ˆë‹¤. ì—­ì‚¬, ê³¼í•™, ë¬¸í™”, ì¼ìƒìƒí™œ ë“± ì—¬ëŸ¬ ë¶„ì•¼ì— ëŒ€í•´ ì´ì•¼ê¸°í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ê¶ê¸ˆí•œ ì ì´ë‚˜ ë„ì›€ì´ í•„ìš”í•œ ë¶€ë¶„ì´ ìˆë‹¤ë©´ ì–¸ì œë“ ì§€ ë§ì”€í•´ ì£¼ì„¸ìš”!\n",
      "\n",
      "16:46:26 httpx INFO   HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "[user_a] ì§ˆë¬¸: ì €ëŠ” í”„ë¡œê·¸ë˜ë°ì„ ë°°ìš°ê³  ìˆìŠµë‹ˆë‹¤. ë‹¹ì‹ ì€ ì–´ë–¤ ì¼ì„ í•˜ì‹œë‚˜ìš”?\n",
      "[user_a] ì±—ë´‡: í”„ë¡œê·¸ë˜ë°ì„ ë°°ìš°ê³  ê³„ì‹œë‹¤ë‹ˆ ë©‹ì§€ë„¤ìš”! ì €ëŠ” ì£¼ë¡œ ì—¬ëŸ¬ë¶„ì˜ ì§ˆë¬¸ì— ë‹µë³€í•˜ê³ , ì •ë³´ë‚˜ ì¡°ì–¸ì„ ì œê³µí•˜ëŠ” ì—­í• ì„ í•©ë‹ˆë‹¤. í”„ë¡œê·¸ë˜ë° ê´€ë ¨ ì§ˆë¬¸ì´ë‚˜ í•™ìŠµì— ë„ì›€ì´ í•„ìš”í•˜ì‹œë©´ ì–¸ì œë“ ì§€ ë„ì™€ë“œë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì–´ë–¤ ì–¸ì–´ë¥¼ ë°°ìš°ê³  ê³„ì‹ ê°€ìš”? ë˜ëŠ” ì–´ë–¤ ë¶€ë¶„ì—ì„œ ë„ì›€ì´ í•„ìš”í•˜ì‹ ê°€ìš”?\n",
      "\n",
      "16:46:28 httpx INFO   HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "[user_b] ì§ˆë¬¸: ì €ëŠ” ì—­ì‚¬ì— ê´€ì‹¬ì´ ë§ìŠµë‹ˆë‹¤. ë‹¹ì‹ ì€ ì–´ë–¤ ë¶„ì•¼ì— ê´€ì‹¬ì´ ìˆë‚˜ìš”?\n",
      "[user_b] ì±—ë´‡: ì—­ì‚¬ì— ê´€ì‹¬ì´ ë§ìœ¼ì‹œêµ°ìš”! ì—­ì‚¬ì ì¸ ì‚¬ê±´ì´ë‚˜ ì¸ë¬¼ì— ëŒ€í•´ ì´ì•¼ê¸°í•˜ëŠ” ê²ƒì€ ì •ë§ í¥ë¯¸ë¡œìš´ ì¼ì…ë‹ˆë‹¤. ì €ëŠ” ë‹¤ì–‘í•œ ë¶„ì•¼ì— ëŒ€í•œ ì •ë³´ë¥¼ ì œê³µí•  ìˆ˜ ìˆì§€ë§Œ, íŠ¹íˆ ì‚¬ëŒë“¤ê³¼ì˜ ì†Œí†µ, ì§€ì‹ ì „ë‹¬, ê·¸ë¦¬ê³  ë¬¸ì œ í•´ê²°ì— ëŒ€í•œ ê´€ì‹¬ì´ ë§ìŠµë‹ˆë‹¤. ì—­ì‚¬ì™€ ê´€ë ¨ëœ ì§ˆë¬¸ì´ë‚˜ íŠ¹ì • ì‚¬ê±´ì— ëŒ€í•´ ë” ì•Œê³  ì‹¶ìœ¼ì‹  ë¶€ë¶„ì´ ìˆë‹¤ë©´ ë§ì”€í•´ ì£¼ì„¸ìš”! í•¨ê»˜ ì´ì•¼ê¸°í•´ ë³´ì•„ìš”.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ë‘ê°œì˜ ì„¸ì…˜ì„ ë²ˆê°ˆì•„ê°€ë©´ì„œ ëŒ€í™”  RunnableWithMessageHistory ê°€ ê° ì„¸ì…˜ì— ë§ëŠ” ëŒ€í™” ê¸°ë¡ì„ ê´€ë¦¬í•©ë‹ˆë‹¤.\n",
    "sessions = ['user_a','user_b']\n",
    "questions = [\n",
    "    'ì•ˆë…•í•˜ì„¸ìš”, ì €ëŠ” í™ê¸¸ë™ì…ë‹ˆë‹¤. ë‹¹ì‹ ì€ ëˆ„êµ¬ì‹ ê°€ìš”?',   # usre_a ì²«ë²ˆì¬ ì§ˆë¬¸\n",
    "    'ì•ˆë…•í•˜ì„¸ìš”, ì €ëŠ” ì´ìˆœì‹ ì…ë‹ˆë‹¤. ë‹¹ì‹ ì€ ì–´ë–¤ ì¼ì„ í•˜ì‹œë‚˜ìš”?', # user_b ì²«ë²ˆì§¸ ì§ˆë¬¸\n",
    "    'ì €ëŠ” í”„ë¡œê·¸ë˜ë°ì„ ë°°ìš°ê³  ìˆìŠµë‹ˆë‹¤. ë‹¹ì‹ ì€ ì–´ë–¤ ì¼ì„ í•˜ì‹œë‚˜ìš”?', # user_a ë‘ë²ˆì§¸ ì§ˆë¬¸\n",
    "    'ì €ëŠ” ì—­ì‚¬ì— ê´€ì‹¬ì´ ë§ìŠµë‹ˆë‹¤. ë‹¹ì‹ ì€ ì–´ë–¤ ë¶„ì•¼ì— ê´€ì‹¬ì´ ìˆë‚˜ìš”?' # user_b ë‘ë²ˆì§¸ ì§ˆë¬¸\n",
    "]\n",
    "for i, question in enumerate(questions):\n",
    "    session_id = sessions[i % 2]  # ì„¸ì…˜ IDë¥¼ ë²ˆê°ˆì•„ê°€ë©° ì‚¬ìš©\n",
    "    result = chatbot.invoke({'input': question}, config={'configurable': {'session_id': session_id}})\n",
    "    print(f'[{session_id}] ì§ˆë¬¸: {question}')\n",
    "    print(f'[{session_id}] ì±—ë´‡: {result}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "1d0add30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16:46:45 httpx INFO   HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "[user_c] ì§ˆë¬¸: ì €ëŠ” ì² ìˆ˜ì—ìš”, ë°˜ê°‘ìŠµë‹ˆë‹¤.\n",
      "[user_c] ì±—ë´‡: ì•ˆë…•í•˜ì„¸ìš”, ì² ìˆ˜ë‹˜! ë°˜ê°‘ìŠµë‹ˆë‹¤. ì–´ë–»ê²Œ ë„ì™€ë“œë¦´ê¹Œìš”? ê¶ê¸ˆí•œ ì ì´ë‚˜ ì´ì•¼ê¸°í•˜ê³  ì‹¶ì€ ì£¼ì œê°€ ìˆë‹¤ë©´ ë§ì”€í•´ ì£¼ì„¸ìš”.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result = chatbot.invoke({'input': \"ì €ëŠ” ì² ìˆ˜ì—ìš”, ë°˜ê°‘ìŠµë‹ˆë‹¤.\"}, config={'configurable': {'session_id': 'user_c'}})\n",
    "print(f'[user_c] ì§ˆë¬¸: ì €ëŠ” ì² ìˆ˜ì—ìš”, ë°˜ê°‘ìŠµë‹ˆë‹¤.')\n",
    "print(f'[user_c] ì±—ë´‡: {result}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "5c322ec7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16:46:54 httpx INFO   HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'í™ê¸¸ë™ë‹˜ì´ë¼ê³  ë§ì”€í•˜ì…¨ìŠµë‹ˆë‹¤! í˜¹ì‹œ ë” ì•Œê³  ì‹¶ìœ¼ì‹  ë‚´ìš©ì´ë‚˜ ë‹¤ë¥¸ ì§ˆë¬¸ì´ ìˆìœ¼ì‹ ê°€ìš”? ì–¸ì œë“ ì§€ ë§ì”€í•´ ì£¼ì„¸ìš”!'"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = chatbot.invoke({'input': \"ì €ëŠ” ëˆ„êµ¬ë¼êµ¬ìš”?\"}, config={'configurable': {'session_id': 'user_a'}})\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "db16b737",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16:47:00 httpx INFO   HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'ì´ìˆœì‹ ë‹˜ì´ë¼ê³  ë§ì”€í•˜ì…¨ìŠµë‹ˆë‹¤! ì´ìˆœì‹ ì€ ì¡°ì„ ì‹œëŒ€ì˜ ìœ ëª…í•œ ì¥êµ°ìœ¼ë¡œ, ì„ì§„ì™œë€ ë™ì•ˆì˜ ë›°ì–´ë‚œ êµ°ì‚¬ ì „ëµê³¼ ìš©ë§¹ìœ¼ë¡œ ì˜ ì•Œë ¤ì ¸ ìˆìŠµë‹ˆë‹¤. í˜¹ì‹œ ì´ìˆœì‹  ì¥êµ°ì— ëŒ€í•´ ë” ì´ì•¼ê¸°í•˜ê³  ì‹¶ìœ¼ì‹ ê°€ìš”, ì•„ë‹ˆë©´ ë‹¤ë¥¸ ì—­ì‚¬ì  ì¸ë¬¼ì´ë‚˜ ì‚¬ê±´ì— ëŒ€í•´ ê¶ê¸ˆí•œ ì ì´ ìˆìœ¼ì‹ ê°€ìš”?'"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = chatbot.invoke({'input': \"ì €ëŠ” ëˆ„êµ¬ë¼êµ¬ìš”?\"}, config={'configurable': {'session_id': 'user_b'}})\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "0e0e21fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16:47:05 httpx INFO   HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'ì² ìˆ˜ë‹˜ì´ë¼ê³  ë§ì”€í•˜ì…¨ìŠµë‹ˆë‹¤! í˜¹ì‹œ ë” ê¶ê¸ˆí•œ ì ì´ë‚˜ ë‹¤ë¥¸ ì´ì•¼ê¸°ë¥¼ ë‚˜ëˆ„ê³  ì‹¶ìœ¼ì‹ ê°€ìš”? ì–¸ì œë“ ì§€ ë§ì”€í•´ ì£¼ì„¸ìš”!'"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = chatbot.invoke({'input': \"ì €ëŠ” ëˆ„êµ¬ë¼êµ¬ìš”?\"}, config={'configurable': {'session_id': 'user_c'}})\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93024a6b",
   "metadata": {},
   "source": [
    "ìš”ì•½ ë©”ëª¨ë¦¬ êµ¬í˜„(ëŒ€í™”ë‚´ìš© ìë™ ìš”ì•½)\n",
    "```\n",
    "ê¸´ ëŒ€í™” ë‚´ìš©ì„ ëª¨ë‘ í”„ë¡¬í”„íŠ¸ì— ê¸°ë¡í•˜ëŠ” ê²ƒì€ ë¹„ íš¨ìœ¨ì  -> í”„ë¡¬í”„íŠ¸ì˜ ê¸¸ì´ ì œí•œì— ê±¸ë¦´ ê°€ëŠ¥ì„±ì´ ìˆìŒ\n",
    "Conversation Summary Memory\n",
    "0.3x ë²„ì „ì—ì„œëŠ” ì§ì ‘ ìš”ì•½ìš© ì œì•ˆì„ ë§Œë“¤ì–´ì„œ ChatMessageHistoryì— ì ìš©\n",
    "```\n",
    "ì–´ë–»ê²Œ ìš”ì•½?\n",
    "```\n",
    "- ì¼ì •ê¸¸ì´ ì´ìƒìœ¼ë¡œ ëŒ€í™”ê°€ ëˆ„ì ë˜ë©´, ê³¼ê±° ëŒ€í™”ë¥¼ ìš”ì•½í•´ì„œ í•µì‹¬ë‚´ìš©ë§Œ ë‹´ê¹€\n",
    "- ìš”ì•½ê²°ê³¼ë¥¼ ë©”ëª¨ë¦¬ì— ì‹œìŠ¤í…œ ë©”ì„¸ì§€ ë“±ìœ¼ë¡œ ì €ì¥ -> ë©”ëª¨ë¦¬ ì ˆì•½\n",
    "- ìƒˆë¡œìš´ ì‚¬ìš©ì ì…ë ¥ì‹œ ìš”ì•½ëœ ë§¥ë½ + ìµœê·¼ ë° ë©”ì„¸ì§€ë§Œ ì°¸ê³ í•´ì„œ llm ì „ë‹¬\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "d3d3a8b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ìš”ì•½ìš© í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿\n",
    "summary_prompt = ChatPromptTemplate.from_messages([\n",
    "    ('system','ë‹¹ì‹ ì€ ëŒ€í™” ìš”ì•½ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ëŒ€í™”ì˜ ì£¼ìš” ë‚´ìš©ì„ ê°„ê²°í•˜ê²Œ ìš”ì•½í•´ ì£¼ì„¸ìš”'),\n",
    "    ('human','{conversation}') # ì „ì²´ ëŒ€í™”ë‚´ìš©ì„ í•˜ë‚˜ì˜ ë¬¸ìì—´ë¡œ ì „ë‹¬\n",
    "])\n",
    "# LCEL\n",
    "summary_chain = summary_prompt | llm | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "cf9e4b4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17:25:51 httpx INFO   HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "17:25:53 httpx INFO   HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "17:25:55 httpx INFO   HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "17:25:58 httpx INFO   HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "17:25:59 httpx INFO   HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "ìš”ì•½ì „ user_dì˜ ë©”ëª¨ë¦¬ ë©”ì„¸ì§€ ê°œìˆ˜ : 30\n"
     ]
    }
   ],
   "source": [
    "# user_d ì„¸ì…˜ì— ëŒ€í™” ë‚´ìš©ì„ ê¸°ë¡ ê¸´ ëŒ€í™” ìƒì„±\n",
    "long_queries = [\n",
    "    'ì•ˆë…•, ì˜¤ëŠ˜ ë­í•˜ë ¤ê³  í–ˆì§€',\n",
    "    'ì•„ ë§ë‹¤ ë‚´ì¼ íšŒì˜ìë£Œ ì¤€ë¹„í•´ì•¼ì§€, íšŒì˜ëŠ” ëª‡ì‹œì§€?',\n",
    "    'ê·¸ íšŒì˜ì— ëˆ„ê°€ ì°¸ì„í•˜ëŠ”ì§€ ê¸°ì–µë‚˜?',\n",
    "    'ë‹¨ìœ„í”„ë¡œì íŠ¸ ì§„í–‰ ìƒí™©ë„ ê³µìœ í•´ì•¼ í• ê¹Œ?',\n",
    "    'ìµœê·¼ì— ì´ì•¼ê¸° í–ˆë˜ ìƒˆë¡œìš´ ê¸°ëŠ¥ì— ëŒ€í•œ ì—…ë°ì´ëŠ” ìˆì–´?'\n",
    "]\n",
    "session_id = 'user_d'\n",
    "for q in long_queries:\n",
    "    answer =  chatbot.invoke({'input': q}, config={'configurable': {'session_id': session_id}})\n",
    "    # print(answer)\n",
    "\n",
    "print(f'ìš”ì•½ì „ user_dì˜ ë©”ëª¨ë¦¬ ë©”ì„¸ì§€ ê°œìˆ˜ : {len(store[session_id].messages)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "7bc0992f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== ìš”ì•½ ë‚´ìš© ==\n",
      "ëŒ€í™” ìš”ì•½:\n",
      "\n",
      "- ì¸ê°„ì€ ì˜¤ëŠ˜ì˜ ê³„íšì„ ë¬»ê³ , AIëŠ” ë‹¤ì–‘í•œ í™œë™ì„ ì œì•ˆí•¨.\n",
      "- ì¸ê°„ì€ ë‚´ì¼ íšŒì˜ ìë£Œ ì¤€ë¹„ë¥¼ ì–¸ê¸‰í•˜ë©° íšŒì˜ ì‹œê°„ì„ ë¬¼ìŒ. AIëŠ” ì´ë©”ì¼ì´ë‚˜ ìº˜ë¦°ë”ì—ì„œ í™•ì¸í•˜ë¼ê³  ì¡°ì–¸.\n",
      "- ì¸ê°„ì€ íšŒì˜ ì°¸ì„ìë¥¼ ê¸°ì–µí•˜ì§€ ëª»í•˜ê³ , AIëŠ” ì´ˆëŒ€ì¥ì´ë‚˜ íŒ€ì›ì—ê²Œ ë¬¸ì˜í•˜ë¼ê³  ì•ˆë‚´.\n",
      "- ì¸ê°„ì€ ë‹¨ìœ„ í”„ë¡œì íŠ¸ ì§„í–‰ ìƒí™© ê³µìœ  ì—¬ë¶€ë¥¼ ì§ˆë¬¸í•˜ê³ , AIëŠ” ê³µìœ ì˜ ì¤‘ìš”ì„±ì„ ê°•ì¡°í•˜ë©° ë„ì›€ì„ ì œì•ˆ.\n",
      "- ì¸ê°„ì€ ìƒˆë¡œìš´ ê¸°ëŠ¥ì— ëŒ€í•œ ì—…ë°ì´íŠ¸ë¥¼ ë¬»ê³ , AIëŠ” ê´€ë ¨ íŒ€ì›ì—ê²Œ ë¬¸ì˜í•˜ë¼ê³  ì¡°ì–¸í•˜ë©° íšŒì˜ì—ì„œ ê³µìœ í•  ê²ƒì„ ì¶”ì²œ.\n"
     ]
    }
   ],
   "source": [
    "# ì „ì²´ ëŒ€í™” ë‚´ìš©ì„ ìš”ì•½í•˜ê³  ë§ˆì§€ë§‰ ì‚¬ìš©ì²˜ ì§ˆë¬¸-ë‹µë³€ ìŒë§Œ ì›ë³¸ ìœ ì§€\n",
    "from langchain_core.messages import SystemMessage, HumanMessage, AIMessage\n",
    "# ìš”ì•½ ëŒ€ìƒ ëŒ€í™”ë‚´ìš© ì¶”ì¶œ(ë§ˆì§€ë§‰ QA ìŒ ì œì™¸í•œ ì´ì „ ë‚´ìš©)\n",
    "message = store[session_id].messages\n",
    "if len(message) > 2:\n",
    "   original_dialog = '\\n'.join([f'{msg.type.upper()} : {msg.content}' for msg in message[:-2]])\n",
    "else:\n",
    "   original_dialog = '\\n'.join([f'{msg.type.upper()} : {msg.content}' for msg in message])\n",
    "\n",
    "# llmìœ¼ë¡œ ìš”ì•½ ìƒ˜í”Œ\n",
    "summary_text = summary_chain.invoke({'conversation':original_dialog})\n",
    "print('== ìš”ì•½ ë‚´ìš© ==')\n",
    "print(summary_text)\n",
    "# ê¸°ì¡´ ë©”ëª¨ë¦¬ë¥¼ ìš”ì•½ìœ¼ë¡œêµì²´ -> ì´ì „ ë‚´ìš© ìš”ì•½ë³¸ +  ìµœê·¼ QA ìœ ì§€\n",
    "new_history = InMemoryChatMessageHistory()\n",
    "new_history.messages.append(SystemMessage(content=f'ìš”ì•½:{summary_text}'))\n",
    "# ìµœê·¼ ëŒ€í™”ì˜ ë§ˆì§€ë§‰ QAìŒì„ ë³µì›\n",
    "if len(message) >= 2:\n",
    "    last_user_msg = message[-2]\n",
    "    last_ai_msg = message[-1]\n",
    "\n",
    "    if isinstance(last_user_msg, HumanMessage):\n",
    "        new_history.add_user_message(last_user_msg.content)\n",
    "    else:\n",
    "        new_history.messages.append(last_user_msg)\n",
    "\n",
    "    if isinstance(last_ai_msg, AIMessage):\n",
    "        new_history.add_ai_message(last_ai_msg)\n",
    "    else:\n",
    "        new_history.messages.append(last_ai_msg)\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "46f2d626",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(store[session_id].messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e17bb7d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
